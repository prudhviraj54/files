import unittest
from pyspark.sql import SparkSession
from my_module import process_data
from rules import fraud_document_analytics

class MySparkTestCase(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        # Create a SparkSession for testing
        cls.spark = SparkSession.builder.master("local").appName("unittest").getOrCreate()
    
    @classmethod
    def tearDownClass(cls):
        # Stop the SparkSession after testing
        cls.spark.stop()

    def test_has_dollar_symbol(self):
        # Define the test DataFrame
        input_data =  [("test1.jpg", "Payment made to cashier with cash of $2000.00 ", "para",30.32), 
                        ("test2.jpg", "Transaction was done using cash in costco", "mil",10.2),
                            ("test3.jpg","User with register no: 58290 used debit card for payment","bil",27.9)]
        headers = ("file_name", "content", "page_label","hand")
        #df = sc.createDataFrame(data, headers)
        input_df = self.spark.createDataFrame(input_data, headers)
        
        # Call the function to be tested
        result_df = fraud_document_analytics.has_dollar_symbol(input_df)
        
        # Define the expected result
        expected_data = [("test1.jpg", "Payment made to cashier with cash of 2000.00 ", "para",30.32,False), 
                        ("test2.jpg", "Transaction was done using cash in costco", "mil",10.2,True),
                            ("test3.jpg","User with register no: 58290 used debit card for payment","bil",27.9,True)]
        headers_exp = ("file_name", "content", "page_label","hand","no_dollar_symbol")
        expected_df = self.spark.createDataFrame(expected_data, headers_exp)
        
        # Compare the actual and expected DataFrames
        #self.assertDataFrameEqual(result_df, expected_df)
        assert sorted(expected_df.collect()) == sorted(result_df.collect())
    def test_handwritten_check(self):
        # Define the test DataFrame
        input_data =  [("test1.jpg", "Payment made to cashier with cash of $2000.00 ", "para",30.32), 
                        ("test2.jpg", "Transaction was done using cash in costco", "mil",10.2),
                            ("test3.jpg","User with register no: 58290 used debit card for payment","bil",27.9)]
        headers = ("file_name", "content", "page_label","hand")
        #df = sc.createDataFrame(data, headers)
        input_df = self.spark.createDataFrame(input_data, headers)
        
        # Call the function to be tested
        result_df = fraud_document_analytics.handwritten_check(input_df,15)
        
        # Define the expected result
        expected_data = [("test1.jpg", "Payment made to cashier with cash of 2000.00 ", "para",30.32,True), 
                        ("test2.jpg", "Transaction was done using cash in costco", "mil",10.2,False),
                            ("test3.jpg","User with register no: 58290 used debit card for payment","bil",27.9,True)]
        headers_exp = ("file_name", "content", "page_label","hand","above_handwritten_threshold")
        expected_df = self.spark.createDataFrame(expected_data, headers_exp)
        
        # Compare the actual and expected DataFrames
        #self.assertDataFrameEqual(result_df, expected_df)
        assert sorted(expected_df.collect()) == sorted(result_df.collect())
    def test_get_reg_num(self):
        # Define the test DataFrame
        input_data =  [("test1.jpg", "Payment made to cashier with cash of $2000.00 ", "para",30.32), 
                        ("test2.jpg", "Transaction was done using cash in costco", "mil",10.2),
                            ("test3.jpg","User with register no: 58290 used debit card for payment","bil",27.9)]
        headers = ("file_name", "content", "page_label","hand")
        #df = sc.createDataFrame(data, headers)
        input_df = self.spark.createDataFrame(input_data, headers)
        
        # Call the function to be tested
        result_df = fraud_document_analytics.get_reg_num(input_df)
        
        # Define the expected result
        expected_data = [("test1.jpg", "Payment made to cashier with cash of 2000.00 ", "para",30.32,null,"No Register Num"), 
                        ("test2.jpg", "Transaction was done using cash in costco", "mil",10.2,null,"No Register Num"),
                            ("test3.jpg","User with register no: 58290 used debit card for payment","bil",27.9,58290)]
        headers_exp = ("file_name", "content", "page_label","hand","register_num")
        expected_df = self.spark.createDataFrame(expected_data, headers_exp)
        
        # Compare the actual and expected DataFrames
        #self.assertDataFrameEqual(result_df, expected_df)
        assert sorted(expected_df.collect()) == sorted(result_df.collect())

    def test_process_data(self):
        # Define the test DataFrame
        input_data =  [("test1.jpg", "Payment made to cashier with cash of 2000.00 ", "para",30.32), 
                        ("test2.jpg", "Transaction was done using cash in costco", "mil",10.2),
                            ("test3.jpg","User with register no: 58290 used debit card for payment","bil",27.9)]
        headers = ("file_name", "content", "page_label","hand")
        #df = sc.createDataFrame(data, headers)
        input_df = self.spark.createDataFrame(input_data, headers)
        
        # Call the function to be tested
        result_df = fraud_document_analytics.paid_by_cash(input_df)
        
        # Define the expected result
        expected_data = [("test1.jpg", "Payment made to cashier with cash of 2000.00 ", "para",30.32,"Ture"), 
                        ("test2.jpg", "Transaction was done using cash in costco", "mil",10.2,"False"),
                            ("test3.jpg","User with register no: 58290 used debit card for payment","bil",27.9),"False"]
        headers_exp = ("file_name", "content", "page_label","hand","paid_by_cash")
        expected_df = self.spark.createDataFrame(expected_data, ["id", headers_exp)
        
        # Compare the actual and expected DataFrames
        self.assertDataFrameEqual(result_df, expected_df)

    ############
    #for form recognizer

    def test_check_stamp(self):
        # Create a test DataFrame
        data = [
            ('file1.txt', 'Some content'),
            ('file2.txt', 'Another content with costco'),
            ('file3.txt', 'Yet another content'),
        ]
        schema = ['file_name', 'content']
        test_df = self.spark.createDataFrame(data, schema)

        # Define the list of files to check
        files_list = ['file1.txt', 'file2.txt']

        # Call the function to test
        result_df = check_stamp(test_df, files_list)

        # Assert the results
        expected_data = [
            ('file1.txt', 'Some content', False),
            ('file2.txt', 'Another content with costco', True),
            ('file3.txt', 'Yet another content', False),
        ]
        expected_schema = ['file_name', 'content', 'has_stamp']
        expected_df = self.spark.createDataFrame(expected_data, expected_schema)

        # Collect and compare the actual and expected DataFrames
        actual_rows = result_df.orderBy('file_name').collect()
        expected_rows = expected_df.orderBy('file_name').collect()

        for actual, expected in zip(actual_rows, expected_rows):
            self.assertEqual(actual, expected)

####another test
    def test_handwritten_percentage(self):
        # Create a test DataFrame schema
        schema = StructType([
            StructField('batch_name', StringType(), False),
            StructField('styles', ArrayType(StructType([
                StructField('spans', ArrayType(StructType([
                    StructField('length', DoubleType(), False)
                ])))
            ]))),
            StructField('content', StringType(), False)
        ])

        # Create test data
        data = [
            ('batch1', [{'spans': [{'length': 5.0}, {'length': 7.0}]}, {'spans': [{'length': 3.0}]}], 'Handwritten content 1']),
            ('batch2', None, 'Typed content 1'),
            ('batch3', [{'spans': [{'length': 10.0}]}], 'Handwritten content 2'),
        ]
        test_df = self.spark.createDataFrame(data, schema)

        # Call the function to test
        result_df = handwritten_per(test_df['batch_name'], test_df)

        # Assert the results
        expected_data = [
            ('batch1', [{'spans': [{'length': 5.0}, {'length': 7.0}]}, {'spans': [{'length': 3.0}]}], 'Handwritten content 1', 0.348),
            ('batch2', None, 'Typed content 1', 0.0),
            ('batch3', [{'spans': [{'length': 10.0}]}], 'Handwritten content 2', 0.909),
        ]
        expected_schema = schema.add(StructField('handwritten_percentage', DoubleType(), False))
        expected_df = self.spark.createDataFrame(expected_data, expected_schema)

        # Collect and compare the actual and expected DataFrames
        actual_rows = result_df.orderBy('batch_name').collect()
        expected_rows = expected_df.orderBy('batch_name').collect()

        for actual, expected in zip(actual_rows, expected_rows):
            self.assertEqual(actual, expected)
# Mocked dataframe with content
        test_data = [
            ('claim_page_one', 'Some content'),
            ('claim_page_two', 'Some other content'),
            ('drug_receipt', 'Drug receipt content'),
            ('paramedical invoice', 'Paramedical invoice content'),
            ('other_receipt', 'Other receipt content'),
            ('other_doc', 'Other doc content')
        ]
        schema = ['page_label', 'content']
        test_df = self.spark.createDataFrame(test_data, schema)

        # Call the function to test
        result_df = sort_document('batch1', test_df)

        # Assert the results
        expected_data = [
            ('claim_page_one', 'Some content'),
            ('claim_page_two', 'Some other content'),
            ('drug_receipt', 'Drug receipt content'),
            ('paramedical invoice', 'Paramedical invoice content'),
            ('other_receipt', 'Other receipt content'),
            ('other_doc', 'Other doc content')
        ]
        expected_df = self.spark.createDataFrame(expected_data, schema)


if __name__ == "__main__":
    unittest.main()
